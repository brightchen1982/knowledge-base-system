 ollama:
  host: 'ollama'
  port: 11434
  timeout: 120

models:
  default: 'deepseek-v3'
  embeddings: 'deepseek-embeddings'
  available:
    - 'deepseek-v3'
    - 'deepseek-r1'
    - 'deepseek-embeddings'

inference:
  temperature: 0.7
  top_p: 0.9
  top_k: 40
  max_tokens: 2048
  stop_sequences: []
